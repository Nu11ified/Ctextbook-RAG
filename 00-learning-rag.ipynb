{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run a local RAG pipeline\n",
    "\n",
    "We will use Google Collab to run this pipeline as they have dedicated GPUs for processing the model.\n",
    "\n",
    "RAG stands for retrival augmented generation\n",
    "\n",
    "RAG can help improve information processed through getting trained on specific models\n",
    "\n",
    "This specific RAG will be parsing the 2008 C Programming Textbook Written by K.N. King \n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Open the PDF\n",
    "2. Format the text of the PDF to be ready for embedding the model\n",
    "3. Embed all the chunks of text in the textbook and turn them into numerical representations (embedding)\n",
    "4. Build a retrival system that uses a vector search to find a relevant chunk of text based on a query\n",
    "5. Create a prompt that incorperates the retrieve pieces of text\n",
    "6. Generate an answer to a query based on the passages of text from the embedding with an LLM \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ctextbook.pdf exists already.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# get the pdf from the path \n",
    "pdf_path = \"ctextbook.pdf\"\n",
    "\n",
    "# download if not existing\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"[INFO] File doesn't exist, attempting download...\")\n",
    "\n",
    "    #URL of PDF\n",
    "    URL = \"https://dn790000.ca.archive.org/0/items/c-programming-a-modern-approach-2nd-ed-c-89-c-99-king-by/C%20Programming%20-%20A%20Modern%20Approach%20-%202nd_Ed%28C89%2C%20c99%29%20-%20King%20by%20_text.pdf\"\n",
    "    # Download the file\n",
    "    response = requests.get(URL)\n",
    "    \n",
    "    # Check if download was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write content to file\n",
    "        with open(pdf_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"[INFO] Successfully downloaded {pdf_path}\")\n",
    "    else:\n",
    "        print(f\"[ERROR] Failed to download file. Status code: {response.status_code}\")\n",
    "else: \n",
    "    print(f\"File {pdf_path} exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c49d44cc4a461db5a460325f23c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -25,\n",
       "  'page_char_count': 65,\n",
       "  'page_word_count': 11,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 16.25,\n",
       "  'text': 'K.N.KING Covers both C89 and C99 A Modern Approach SECOND EDITION'},\n",
       " {'page_number': -24,\n",
       "  'page_char_count': 2019,\n",
       "  'page_word_count': 317,\n",
       "  'page_sentence_count_raw': 13,\n",
       "  'page_token_count': 504.75,\n",
       "  'text': 'K.N.KING The first, edition of C Pivgmmimm/: A Modem Approach was a hit with students and faculty alike because of its clarify arid comprehensiveness as well as its trademark Q&A sections. King’s spiral approach made the first edition accessible to n broad range of readers, from beginners to more advanced st udents. The first edition was used at over 225 colleges, making it. one of the leading C textbooks of the last ten years. FEATURES OF THE SECOND EDITION Complete coverage of both the CS9 standard and the C99 standard, with all C99 changes clearly marked Includes a quick reference to all C89 and G99 library functions • Expanded coverage of GCC New coverage of abstract data types Updated to reflect today\\'s CPUs and operating systems * Nearly 500 exercises and programming projects—60% more than in the first edition Source code and solutions to selected exercises and programming projects for students, available at the author’s website (lcttJcittg.com) Password-protected instructor site (also at knking.com) containing solutions to the remaining exercises and projects, plus PowerPoint presentations for most chapters \"I thoroughly enjoyed reading the second edition of C Programming and I look forward to using it in future courses.\" — Karen Reid, Senior Lecturer, Department of Computer Science, University of Toronto \"The second edition of King\\'s C Programming improves on an already impressive base, and is the book I recommend to anyone who wants to leargX\" — Peter Seebach, moderator. comp. lang. c. modera ted \"I assign C Programming to first- year engineering students. It is concise, clear, accessible to the beginner, and yet also covers all aspects of the language.\" — Professor Markus Bussmann, Department of Mechanical and Industrial Engineering, University of Toronto K. N. KING (Ph.D., University of California, Berkeley) is an associate professor of computer science at Georgia State University. He is also the author of Modula-2: A Complete Guide and Java Programming: From the Beginning.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the PDF \n",
    "import fitz \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Format text from PDF for processing while preserving important structure.\n",
    "    Cleans text but maintains chapter titles and important formatting.\n",
    "    \"\"\"\n",
    "    # Remove excessive whitespace and normalize line breaks\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    cleaned_text = \" \".join(cleaned_text.split())\n",
    "    \n",
    "    # Preserve chapter markers and section headers\n",
    "    # Look for patterns like \"Chapter X\" or \"Section X.Y\"\n",
    "    import re\n",
    "    \n",
    "    # Add line breaks before chapter/section headers for better parsing\n",
    "    cleaned_text = re.sub(r'(Chapter\\s+\\d+)', r'\\n\\1', cleaned_text)\n",
    "    cleaned_text = re.sub(r'(Section\\s+\\d+\\.?\\d*)', r'\\n\\1', cleaned_text)\n",
    "    \n",
    "    # Clean up any double line breaks\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', cleaned_text)\n",
    "    \n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_texts.append({\"page_number\": page_number - 25,\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text)/4,\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "    \n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>16.25</td>\n",
       "      <td>K.N.KING Covers both C89 and C99 A Modern Appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-24</td>\n",
       "      <td>2019</td>\n",
       "      <td>317</td>\n",
       "      <td>13</td>\n",
       "      <td>504.75</td>\n",
       "      <td>K.N.KING The first, edition of C Pivgmmimm/: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23</td>\n",
       "      <td>1777</td>\n",
       "      <td>311</td>\n",
       "      <td>13</td>\n",
       "      <td>444.25</td>\n",
       "      <td>PREFACE In computing, turning the obvious into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-22</td>\n",
       "      <td>3041</td>\n",
       "      <td>492</td>\n",
       "      <td>35</td>\n",
       "      <td>760.25</td>\n",
       "      <td>Includes a quick reference to all C89 and C99 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-21</td>\n",
       "      <td>2860</td>\n",
       "      <td>475</td>\n",
       "      <td>36</td>\n",
       "      <td>715.00</td>\n",
       "      <td>Preface xxiii I’ve also taken the opportunity ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0          -25               65               11                        1   \n",
       "1          -24             2019              317                       13   \n",
       "2          -23             1777              311                       13   \n",
       "3          -22             3041              492                       35   \n",
       "4          -21             2860              475                       36   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0             16.25  K.N.KING Covers both C89 and C99 A Modern Appr...  \n",
       "1            504.75  K.N.KING The first, edition of C Pivgmmimm/: A...  \n",
       "2            444.25  PREFACE In computing, turning the obvious into...  \n",
       "3            760.25  Includes a quick reference to all C89 and C99 ...  \n",
       "4            715.00  Preface xxiii I’ve also taken the opportunity ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>389.50</td>\n",
       "      <td>1948.82</td>\n",
       "      <td>334.80</td>\n",
       "      <td>17.04</td>\n",
       "      <td>487.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.74</td>\n",
       "      <td>559.30</td>\n",
       "      <td>98.17</td>\n",
       "      <td>8.48</td>\n",
       "      <td>139.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>182.25</td>\n",
       "      <td>1638.50</td>\n",
       "      <td>279.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>409.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>389.50</td>\n",
       "      <td>1990.00</td>\n",
       "      <td>341.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>497.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>596.75</td>\n",
       "      <td>2319.25</td>\n",
       "      <td>400.75</td>\n",
       "      <td>21.00</td>\n",
       "      <td>579.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>804.00</td>\n",
       "      <td>3434.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>858.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       830.00           830.00           830.00                   830.00   \n",
       "mean        389.50          1948.82           334.80                    17.04   \n",
       "std         239.74           559.30            98.17                     8.48   \n",
       "min         -25.00             0.00             1.00                     1.00   \n",
       "25%         182.25          1638.50           279.25                    12.00   \n",
       "50%         389.50          1990.00           341.50                    17.00   \n",
       "75%         596.75          2319.25           400.75                    21.00   \n",
       "max         804.00          3434.00           637.00                    55.00   \n",
       "\n",
       "       page_token_count  \n",
       "count            830.00  \n",
       "mean             487.20  \n",
       "std              139.82  \n",
       "min                0.00  \n",
       "25%              409.62  \n",
       "50%              497.50  \n",
       "75%              579.81  \n",
       "max              858.50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind we cannot pass infinite tokens through the textbook to any LLM as \n",
    "\n",
    "Embedding models don't deal with infinite tokens, LLMs dont have infinite tokens, and is computational wasteful as an embedding model are trained to embed sequences to 384 tokens into numerical space. That is the model we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x17b22f690>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English \n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline \n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1105e62e0e7449adb7ff6599ca20293b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Make sure all sentences are strings (the default type is spacy datatype)\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    # Count the sentences\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 696,\n",
       "  'page_char_count': 1887,\n",
       "  'page_word_count': 338,\n",
       "  'page_sentence_count_raw': 6,\n",
       "  'page_token_count': 471.75,\n",
       "  'text': '26.3 The <time.h> Header: Date and Time 697 Table 26.2 Conversion Specifiers for the strf time Function Conversion Replacement %a Abbreviated weekday name (e.g.. Sun) %A Full weekday name (e.g.. Sunday) %b Abbreviated month name (e.g.. Jun) %B Full month name (e.g., June) %c Complete day and time (e.g.. Sun Jun 3 17:48:34 2007) %Cf Year divided by 100 and truncated to an integer (00-99) %d Day of month (01-31) %D* Equivalent to %m/%d/%y %e\\' Day of month (1—31); a single digit is preceded by a space %F7 Equivalent to %Y-%m-%d %g‘ Last two digits of ISO 8601 week-based year (00-99) %G’ ISO 8601 week-based year %h: Equivalent to %b %H Hour on 24-hour clock (00-23) %I Hour on 12-hour clock (01-12) %j Day of year (001-366) %m Month (01-12) %M Minute (00-59) %n; New-line character %p AM/PM designator (AM or PM) %r\\' 12-hour clock time (e.g., 05 : 48 :34 PM) %R{ Equivalent to %H: %M %S Second (00-61); maximum value in C99 is 60 %tf Horizontal-tab character %T+ Equivalent to %H: %M: %S %u* ISO 8601 weekday (1-7); Monday is I %U Week number (00-53); first Sunday is beginning of week 1 %V+ ISO 8601 week number (01-53) %w Weekday (0-6); Sunday is 0 %W Week number (00-53); first Monday is beginning of week I %x Complete date (e.g., 06/03/07) %X Complete time (e.g., 17:48:34) %y Last two digits of year (00-99) %Y Year %z’ Offset from UTC’ in ISO 8601 format (e.g., -0530 or +0200) %Z Time zone name or abbreviation (e.g.. EST) %% % fC99 only Table 26.3 Conversion Replacement - - — ■ —11, 1 Replacement Strings for %a First three characters of %A strf time Conversion %A One of \"Sunday\", \"Monday\".\"Saturday\" Specifiers in the %b First three characters of %B \"C\" Locale %B One of \"January\", \"February\".\"December\" %c Equivalent to \" %a %b %e %T %Y\" %p One of \"AM\" or \"PM\" %r Equivalent to \" % I: %M: %S %p \" %x Equivalent to \"%m/%d/%y\" %X Equivalent to %T %z Implementation-defined',\n",
       "  'sentences': ['26.3 The <time.h> Header: Date and Time 697 Table 26.2 Conversion Specifiers for the strf time Function Conversion Replacement %a Abbreviated weekday name (e.g.. Sun) %A Full weekday name (e.g.. Sunday) %b Abbreviated month name (e.g.. Jun) %B Full month name (e.g., June) %c Complete day and time (e.g.. Sun Jun 3 17:48:34 2007) %Cf Year divided by 100 and truncated to an integer (00-99) %d Day of month (01-31) %D* Equivalent to %m/%d/%y %e\\' Day of month (1—31); a single digit is preceded by a space %F7 Equivalent to %Y-%m-%d %g‘ Last two digits of ISO 8601 week-based year (00-99) %G’ ISO 8601 week-based year %h: Equivalent to %b %H Hour on 24-hour clock (00-23) %I Hour on 12-hour clock (01-12) %j Day of year (001-366) %m Month (01-12) %M Minute (00-59) %n; New-line character %p AM/PM designator (AM or PM) %r\\' 12-hour clock time (e.g., 05 : 48 :34 PM) %R{ Equivalent to %H: %M %S Second (00-61); maximum value in C99 is 60 %tf Horizontal-tab character %T+ Equivalent to %H: %M: %S %u* ISO 8601 weekday (1-7); Monday is I %U Week number (00-53); first Sunday is beginning of week 1 %V+ ISO 8601 week number (01-53) %w Weekday (0-6); Sunday is 0 %W Week number (00-53); first Monday is beginning of week I %x Complete date (e.g., 06/03/07) %X Complete time (e.g., 17:48:34) %y Last two digits of year (00-99) %Y Year %z’ Offset from UTC’ in ISO 8601 format (e.g., -0530 or +0200) %Z Time zone name or abbreviation (e.g.. EST) %% % fC99 only Table 26.3 Conversion Replacement - - — ■ —11, 1 Replacement Strings for %a First three characters of %A strf time Conversion %A One of \"Sunday\", \"Monday\".',\n",
       "   '\"Saturday\" Specifiers in the %b First three characters of %B \"C\" Locale %B One of \"January\", \"February\".',\n",
       "   '\"December\" %c Equivalent to \" %a %b %e %T %Y\" %p One of \"AM\" or \"PM\" %r Equivalent to \" % I: %M: %S %p \" %x Equivalent to \"%m/%d/%y\" %X Equivalent to %T %z Implementation-defined'],\n",
       "  'page_sentence_count_spacy': 3}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>389.50</td>\n",
       "      <td>1948.82</td>\n",
       "      <td>334.80</td>\n",
       "      <td>17.04</td>\n",
       "      <td>487.20</td>\n",
       "      <td>17.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.74</td>\n",
       "      <td>559.30</td>\n",
       "      <td>98.17</td>\n",
       "      <td>8.48</td>\n",
       "      <td>139.82</td>\n",
       "      <td>8.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>182.25</td>\n",
       "      <td>1638.50</td>\n",
       "      <td>279.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>409.62</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>389.50</td>\n",
       "      <td>1990.00</td>\n",
       "      <td>341.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>497.50</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>596.75</td>\n",
       "      <td>2319.25</td>\n",
       "      <td>400.75</td>\n",
       "      <td>21.00</td>\n",
       "      <td>579.81</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>804.00</td>\n",
       "      <td>3434.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>858.50</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       830.00           830.00           830.00                   830.00   \n",
       "mean        389.50          1948.82           334.80                    17.04   \n",
       "std         239.74           559.30            98.17                     8.48   \n",
       "min         -25.00             0.00             1.00                     1.00   \n",
       "25%         182.25          1638.50           279.25                    12.00   \n",
       "50%         389.50          1990.00           341.50                    17.00   \n",
       "75%         596.75          2319.25           400.75                    21.00   \n",
       "max         804.00          3434.00           637.00                    55.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count            830.00                     830.00  \n",
       "mean             487.20                      17.15  \n",
       "std              139.82                       8.13  \n",
       "min                0.00                       0.00  \n",
       "25%              409.62                      11.00  \n",
       "50%              497.50                      17.00  \n",
       "75%              579.81                      22.00  \n",
       "max              858.50                      50.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next chunking our sentences \n",
    "\n",
    "We will split the groups into 10 sentences. There are frameworks such as langchain that will work with this but we will do it in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "\n",
    "num_sentence_chunk_size = 10\n",
    "\n",
    "# create a function split lists of texts recursively into chunk size\n",
    "# e.g. 20 _> [10, 10] or [25] -> [10, 10, 5]\n",
    "\n",
    "def split_list(input_list: list,\n",
    "               slize_size: int=num_sentence_chunk_size) -> list[list[str]]:\n",
    "    return [input_list[i:i+slize_size] for i in range(0, len(input_list), slize_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9403b69a2b964ae689ee5760814fb754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loop through the pages and texts and split them into chunks\n",
    "\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                          slize_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 700,\n",
       "  'page_char_count': 3002,\n",
       "  'page_word_count': 513,\n",
       "  'page_sentence_count_raw': 23,\n",
       "  'page_token_count': 750.5,\n",
       "  'text': 'Q&A 701 A: Some C libraries supply functions with names like itoa that convert numbers to strings. Using these functions isn’t a great idea, though: they aren\\'t part of the C standard and won\\'t be portable. The best way to perform this kind of conversion is eprintf function >22.8 to call a function such as sprint f that writes formatted output into a siring: char str[20]; int i ; sprintf(str, \"%d\", i); /* writes i into the string str */ Not only is sprintf portable, but it also provides a great deal of control over the appearance of the number. *Q: The description of the str tod function says that C99 allows the string argu¬ ment to contain a hexadecimal floating-point number, infinity, or NaN. What is the format of these numbers? [p. 684] A: A hexadecimal floating-point number begins with Ox or OX. followed by one or more hexadecimal digits (possibly including a decimal-point character), and then possibly a binary exponent. (See the Q&A at the end of \\nChapter 7 for a discus¬ sion of hexadecimal floating constants, which have a similar—but not identical— format.) Infinity has the form INF or INFINITY: any or all of the letters may be lower-case. NaN is represented by the string NAN (again ignoring case), possibly followed by a pair of parentheses. The parentheses may be empty or they may contain a series of characters, where each character is a letter, digit, or under¬ score. The characters may be used to specify some of the bits in the binary repre¬ sentation of the NaN value, but their exact meaning is implementation-defined. The same kind of character sequence—which the C99 standard calls an n-char- nan function >23.4 sequence—is also used in calls of the nan function. *Q: You said that performing the call exit(n) anywhere in a program is nor¬ mally equivalent to executing the statement return //; in main. When would it not be equivalent? [p. 688] A: There are two issues. First, when the main function returns, the lifetime of its automatic storage duration ► is2 local variables ends (assuming that they have automatic storage duration, as they will unless they\\'re declared to be static), which isn\\'t true if the exit function is called. A problem will occur if any action that takes place at program termina¬ tion—such as calling a function previously registered using atexit or flushing an output stream buffer—requires access to one of these variables. In particular, a setvbuf function>22.2 program might have called setvbuf and used one of main’s variables as a buffer. Thus, in rare cases a program may behave improperly if it attempts to return from main but work if it calls exit instead. The other issue occurs only in C99. which makes it legal for main to have a return type other than int if an implementation explicitly allows the programmer to do so. In these circumstances, the call exit (n) isn’t necessarily equivalent to executing return n; in main. In fact, the statement return n; may be illegal (if main is declared to return void, for example).',\n",
       "  'sentences': ['Q&A 701 A: Some C libraries supply functions with names like itoa that convert numbers to strings.',\n",
       "   \"Using these functions isn’t a great idea, though: they aren't part of the C standard and won't be portable.\",\n",
       "   'The best way to perform this kind of conversion is eprintf function >22.8 to call a function such as sprint f that writes formatted output into a siring: char str[20]; int i ; sprintf(str, \"%d\", i); /* writes i into the string str */ Not only is sprintf portable, but it also provides a great deal of control over the appearance of the number. *',\n",
       "   'Q: The description of the str tod function says that C99 allows the string argu¬ ment to contain a hexadecimal floating-point number, infinity, or NaN. What is the format of these numbers? [',\n",
       "   'p. 684] A: A hexadecimal floating-point number begins with Ox or OX.',\n",
       "   'followed by one or more hexadecimal digits (possibly including a decimal-point character), and then possibly a binary exponent. (',\n",
       "   'See the Q&A at the end of \\nChapter 7 for a discus¬ sion of hexadecimal floating constants, which have a similar—but not identical— format.)',\n",
       "   'Infinity has the form INF or INFINITY: any or all of the letters may be lower-case.',\n",
       "   'NaN is represented by the string NAN (again ignoring case), possibly followed by a pair of parentheses.',\n",
       "   'The parentheses may be empty or they may contain a series of characters, where each character is a letter, digit, or under¬ score.',\n",
       "   'The characters may be used to specify some of the bits in the binary repre¬ sentation of the NaN value, but their exact meaning is implementation-defined.',\n",
       "   'The same kind of character sequence—which the C99 standard calls an n-char- nan function >23.4 sequence—is also used in calls of the nan function. *',\n",
       "   'Q: You said that performing the call exit(n) anywhere in a program is nor¬ mally equivalent to executing the statement return //; in main.',\n",
       "   'When would it not be equivalent? [',\n",
       "   'p. 688] A: There are two issues.',\n",
       "   \"First, when the main function returns, the lifetime of its automatic storage duration ► is2 local variables ends (assuming that they have automatic storage duration, as they will unless they're declared to be static), which isn't true if the exit function is called.\",\n",
       "   'A problem will occur if any action that takes place at program termina¬ tion—such as calling a function previously registered using atexit or flushing an output stream buffer—requires access to one of these variables.',\n",
       "   'In particular, a setvbuf function>22.2 program might have called setvbuf and used one of main’s variables as a buffer.',\n",
       "   'Thus, in rare cases a program may behave improperly if it attempts to return from main but work if it calls exit instead.',\n",
       "   'The other issue occurs only in C99.',\n",
       "   'which makes it legal for main to have a return type other than int if an implementation explicitly allows the programmer to do so.',\n",
       "   'In these circumstances, the call exit (n) isn’t necessarily equivalent to executing return n; in main.',\n",
       "   'In fact, the statement return n; may be illegal (if main is declared to return void, for example).'],\n",
       "  'page_sentence_count_spacy': 23,\n",
       "  'sentence_chunks': [['Q&A 701 A: Some C libraries supply functions with names like itoa that convert numbers to strings.',\n",
       "    \"Using these functions isn’t a great idea, though: they aren't part of the C standard and won't be portable.\",\n",
       "    'The best way to perform this kind of conversion is eprintf function >22.8 to call a function such as sprint f that writes formatted output into a siring: char str[20]; int i ; sprintf(str, \"%d\", i); /* writes i into the string str */ Not only is sprintf portable, but it also provides a great deal of control over the appearance of the number. *',\n",
       "    'Q: The description of the str tod function says that C99 allows the string argu¬ ment to contain a hexadecimal floating-point number, infinity, or NaN. What is the format of these numbers? [',\n",
       "    'p. 684] A: A hexadecimal floating-point number begins with Ox or OX.',\n",
       "    'followed by one or more hexadecimal digits (possibly including a decimal-point character), and then possibly a binary exponent. (',\n",
       "    'See the Q&A at the end of \\nChapter 7 for a discus¬ sion of hexadecimal floating constants, which have a similar—but not identical— format.)',\n",
       "    'Infinity has the form INF or INFINITY: any or all of the letters may be lower-case.',\n",
       "    'NaN is represented by the string NAN (again ignoring case), possibly followed by a pair of parentheses.',\n",
       "    'The parentheses may be empty or they may contain a series of characters, where each character is a letter, digit, or under¬ score.'],\n",
       "   ['The characters may be used to specify some of the bits in the binary repre¬ sentation of the NaN value, but their exact meaning is implementation-defined.',\n",
       "    'The same kind of character sequence—which the C99 standard calls an n-char- nan function >23.4 sequence—is also used in calls of the nan function. *',\n",
       "    'Q: You said that performing the call exit(n) anywhere in a program is nor¬ mally equivalent to executing the statement return //; in main.',\n",
       "    'When would it not be equivalent? [',\n",
       "    'p. 688] A: There are two issues.',\n",
       "    \"First, when the main function returns, the lifetime of its automatic storage duration ► is2 local variables ends (assuming that they have automatic storage duration, as they will unless they're declared to be static), which isn't true if the exit function is called.\",\n",
       "    'A problem will occur if any action that takes place at program termina¬ tion—such as calling a function previously registered using atexit or flushing an output stream buffer—requires access to one of these variables.',\n",
       "    'In particular, a setvbuf function>22.2 program might have called setvbuf and used one of main’s variables as a buffer.',\n",
       "    'Thus, in rare cases a program may behave improperly if it attempts to return from main but work if it calls exit instead.',\n",
       "    'The other issue occurs only in C99.'],\n",
       "   ['which makes it legal for main to have a return type other than int if an implementation explicitly allows the programmer to do so.',\n",
       "    'In these circumstances, the call exit (n) isn’t necessarily equivalent to executing return n; in main.',\n",
       "    'In fact, the statement return n; may be illegal (if main is declared to return void, for example).']],\n",
       "  'num_chunks': 3}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "      <td>830.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>389.50</td>\n",
       "      <td>1948.82</td>\n",
       "      <td>334.80</td>\n",
       "      <td>17.04</td>\n",
       "      <td>487.20</td>\n",
       "      <td>17.15</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.74</td>\n",
       "      <td>559.30</td>\n",
       "      <td>98.17</td>\n",
       "      <td>8.48</td>\n",
       "      <td>139.82</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>182.25</td>\n",
       "      <td>1638.50</td>\n",
       "      <td>279.25</td>\n",
       "      <td>12.00</td>\n",
       "      <td>409.62</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>389.50</td>\n",
       "      <td>1990.00</td>\n",
       "      <td>341.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>497.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>596.75</td>\n",
       "      <td>2319.25</td>\n",
       "      <td>400.75</td>\n",
       "      <td>21.00</td>\n",
       "      <td>579.81</td>\n",
       "      <td>22.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>804.00</td>\n",
       "      <td>3434.00</td>\n",
       "      <td>637.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>858.50</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       830.00           830.00           830.00                   830.00   \n",
       "mean        389.50          1948.82           334.80                    17.04   \n",
       "std         239.74           559.30            98.17                     8.48   \n",
       "min         -25.00             0.00             1.00                     1.00   \n",
       "25%         182.25          1638.50           279.25                    12.00   \n",
       "50%         389.50          1990.00           341.50                    17.00   \n",
       "75%         596.75          2319.25           400.75                    21.00   \n",
       "max         804.00          3434.00           637.00                    55.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count            830.00                     830.00      830.00  \n",
       "mean             487.20                      17.15        2.15  \n",
       "std              139.82                       8.13        0.85  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              409.62                      11.00        2.00  \n",
       "50%              497.50                      17.00        2.00  \n",
       "75%              579.81                      22.00        3.00  \n",
       "max              858.50                      50.00        5.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split each chunk into its own item\n",
    "\n",
    "Make an embed chunk of sentences into its own numberical representation to give granularity and making it so we can look at specific text samples used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174f7832c6434ffba83480c3e1c26885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "\n",
    "pages_and_chunks = []\n",
    "\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "\n",
    "        # Join the sentences together into paragraph-like structure, aka join the list of sentence into one paragraph\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\" \", \" \").strip()\n",
    "\n",
    "        # Add a space after a period if the next letter is capitalized\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "\n",
    "        # Add the joined sentence chunk to the dictionary\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get some stats on our chunks\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \") if word.strip()])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk)\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 44,\n",
       "  'sentence_chunk': '3.2 The scanf Function 45 Ordinary Characters in Format Strings The concept of pattern-matching can be taken one step further by writing format strings that contain ordinary characters in addition to conversion specifications. The action that scanf takes when it processes an ordinary character in a format string depends on whether or not it’s a white-space character.■ White-space characters. When it encounters one or more consecutive white- space characters in a format string, scanf repeatedly reads white-space char¬ acters from the input until it reaches a non-white-space character (which is \"put back\"). The number of white-space characters in the format string is irrelevant; one white-space character in the format string will match any num¬ ber of white-space characters in the input. (Incidentally, putting a white-space character in a format string doesn’t force the input to contain white-space characters. A white-space character in a format string matches any number of white-space characters in the input, including none.)■ Other characters. When it encounters a non-white-space character in a format string, scanf compares it with the next input character. If the two characters match, scanf discards the input character and continues processing the for¬ mat string.',\n",
       "  'chunk_char_count': 1285,\n",
       "  'chunk_word_count': 193,\n",
       "  'chunk_token_count': 1285}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
